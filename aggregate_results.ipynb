{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import functions\n",
    "import itertools\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listdir_nohidden(path):\n",
    "    for f in os.listdir(path):\n",
    "        if not f.startswith('.'):\n",
    "            yield f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_to_str(n):\n",
    "    if n > 1000:\n",
    "        return \"{0:.4e}\".format(n)\n",
    "    else:\n",
    "        return \"{0:.2f}\".format(n)\n",
    "\n",
    "def print_table(results):\n",
    "    print(\"Function &Best &Worst &Median &$c$ &$\\\\bar\\{v\\}$ &Mean &Std & FRate\\\\\\\\\")\n",
    "    print(\"\\\\midrule\")\n",
    "    for k, v in results.items():\n",
    "        print(\"{0} &{1}({2}) &{3}({4}) &{5}({6}) &{7} &{8} &{9} &{10} &{11}\\\\\\\\\".format(k, \n",
    "                                                                                         number_to_str(v['best_perf']), \n",
    "                                                                                         v['best_consts'], \n",
    "                                                                                         number_to_str(v['worst_perf']), \n",
    "                                                                                         v['worst_consts'], \n",
    "                                                                                         number_to_str(v['median_perf']),\n",
    "                                                                                         v['median_consts'],\n",
    "                                                                                         tuple(v['c']),\n",
    "                                                                                         number_to_str(v['v']),\n",
    "                                                                                         number_to_str(v['mean']),\n",
    "                                                                                         number_to_str(v['std']),\n",
    "                                                                                         v['f_rate']\n",
    "                                                                                         ))\n",
    "\n",
    "def print_table_rev(results):\n",
    "    key_order = [(\"best_perf\", \"Best\"), (\"worst_perf\", \"Worst\"), (\"median_perf\", \"Median\"), (\"c\", \"$c$\"), (\"v\", \"$\\\\bar{v}$\"), (\"mean\", \"Mean\"), (\"std\", \"Std\"), (\"f_rate\", \"F Rate\")]\n",
    "    print(\"\\\\begin{tabular}{c|cccc}\")\n",
    "    print(\"\\\\toprule\")\n",
    "    print(\"&\" + \"&\".join(results.keys()) + \"\\\\\\\\\")\n",
    "    print(\"\\\\midrule\")\n",
    "    for k, n in key_order:\n",
    "        if k == \"best_perf\":\n",
    "            to_print = [f\"{h[0]}({h[1]})\" for h in list(zip([str(d[\"best_perf\"]) for d in results.values()], [str(d[\"best_consts\"]) for d in results.values()]))]\n",
    "            print(n + \"&\" + \"&\".join(to_print) + \"\\\\\\\\\")\n",
    "        elif k == \"worst_perf\":\n",
    "            to_print = [f\"{h[0]}({h[1]})\" for h in list(zip([str(d[\"worst_perf\"]) for d in results.values()], [str(d[\"worst_consts\"]) for d in results.values()]))]\n",
    "            print(n + \"&\" + \"&\".join(to_print) + \"\\\\\\\\\")\n",
    "        else:\n",
    "            print(n + \"&\" + \"&\".join([str(d[k]) for d in results.values()]) + \"\\\\\\\\\")\n",
    "    print(\"\\\\bottomrule\")\n",
    "    print(\"\\\\end{tabular}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function &Best &Worst &Median &$c$ &$\\bar\\{v\\}$ &Mean &Std & FRate\\\\\n",
      "\\midrule\n",
      "C01 &-0.31(1) &-0.23(0) &-0.24(0) &(0, 0, 0) &0.00 &-0.26 &0.02 &1.0\\\\\n",
      "C02 &-1.42(2) &1.63(2) &0.83(1) &(0, 0, 1) &-0.68 &-0.33 &0.77 &0.32\\\\\n",
      "C03 &1.0327e+16(1) &2.0391e+16(1) &1.5209e+16(1) &(0, 0, 1) &9.5157e+06 &1.5342e+16 &2.8087e+15 &0.0\\\\\n",
      "C05 &-238.94(2) &183.60(2) &-84.81(1) &(0, 0, 1) &-2.05 &-95.23 &99.54 &0.0\\\\\n",
      "C06 &-263.19(2) &185.30(2) &-32.91(2) &(1, 0, 1) &20.50 &-66.53 &103.25 &0.0\\\\\n",
      "C07 &7.2260e+05(0) &2.2876e+09(0) &1.8903e+10(1) &(0, 1, 0) &-1.76 &1.5027e+08 &4.4983e+08 &1.0\\\\\n",
      "C08 &6.1726e+05(0) &3.2156e+07(0) &6.1113e+06(1) &(1, 0, 0) &0.00 &5.9129e+06 &7.2139e+06 &1.0\\\\\n",
      "C09 &2.0660e+06(1) &1.5251e+09(1) &7.4218e+08(1) &(0, 1, 0) &-201.99 &2.8231e+08 &3.4578e+08 &0.48\\\\\n",
      "C10 &1.8167e+06(1) &2.9383e+09(1) &6.6833e+08(1) &(1, 0, 0) &131.97 &5.0310e+08 &7.6629e+08 &0.48\\\\\n",
      "C11 &-34.75(1) &-24.39(1) &-27.80(1) &(0, 0, 1) &5.7445e+12 &-28.25 &2.34 &0.0\\\\\n",
      "C12 &-19861.44(2) &-14251.62(1) &-15931.87(2) &(0, 0, 2) &4.5400e+12 &-16803.35 &1.3490e+03 &0.0\\\\\n",
      "C13 &-366.12(2) &-289.73(2) &-333.28(2) &(0, 0, 2) &622.89 &-331.53 &19.30 &0.0\\\\\n",
      "C14 &2.9486e+06(0) &1.1995e+11(1) &9.1124e+08(1) &(1, 0, 0) &-165.56 &5.7529e+09 &2.3366e+10 &1.0\\\\\n",
      "C15 &8.7905e+05(2) &4.0989e+09(1) &3.1182e+07(1) &(0, 0, 1) &-13307.90 &2.0278e+08 &8.0093e+08 &1.0\\\\\n",
      "C16 &0.27(2) &0.71(3) &0.83(3) &(2, 0, 1) &180.10 &0.51 &0.10 &0.04\\\\\n",
      "C17 &10.20(2) &31.50(2) &31.08(3) &(0, 3, 0) &2.7767e+19 &19.51 &5.80 &0.48\\\\\n",
      "C18 &64.80(1) &972.75(1) &308.78(2) &(0, 0, 2) &0.00 &314.20 &218.56 &1.0\\\\\n"
     ]
    }
   ],
   "source": [
    "dimensions = 30\n",
    "logdir_path = 'log/complete_logs/run_30D_crossover/'\n",
    "logdir = Path(logdir_path)\n",
    "results = dict()\n",
    "for c in sorted(listdir_nohidden(logdir)):\n",
    "    runs = len(list(listdir_nohidden(logdir / c)))\n",
    "    best_list = list()\n",
    "    idx_best_list = list()\n",
    "    performances = np.array([])\n",
    "    \n",
    "    function_class = getattr(functions, c)\n",
    "    function_obj = function_class(dimensions=dimensions)\n",
    "    \n",
    "    # feasibility rate\n",
    "    fes = 0\n",
    "    for r in listdir_nohidden(logdir / c):\n",
    "        if r == \"plots\":\n",
    "            continue\n",
    "        s = np.load(logdir / c/ r / \"solutions.npy\")\n",
    "        p = np.load(logdir / c / r / \"performances.npy\")\n",
    "        if len(performances) == 0:\n",
    "            performances = np.array([p])\n",
    "            solutions = np.array([s])\n",
    "        else:\n",
    "            performances = np.concatenate([performances, [p]], axis=0)\n",
    "            solutions = np.concatenate([solutions, [s]], axis=0)\n",
    "        \n",
    "        # take best of this run\n",
    "        idx_best = np.unravel_index(np.nanargmin(p), p.shape)\n",
    "        idx_best_list.append(idx_best)\n",
    "        best_list.append(p[idx_best])\n",
    "        \n",
    "        feasible_solution = False\n",
    "        # check if there is at least one feasible solution in this run to compute the feasible rate\n",
    "        # get all positions where there might be feasible solutions (0 for g and 0/1 for h constraints)\n",
    "        consts = list(function_class.constraints(None).keys())\n",
    "        combinations = list(map(list, itertools.product([0, 1], repeat=len(consts))))\n",
    "        for i, comb in enumerate(combinations):\n",
    "            for const, (k, item) in zip(consts, enumerate(comb)):\n",
    "                if const.startswith('g'):\n",
    "                    combinations[i][k] = 0\n",
    "        # remove duplicates\n",
    "        combinations.sort()\n",
    "        feasible_indexes = list(l for l,_ in itertools.groupby(combinations))\n",
    "        for f_idx in feasible_indexes:\n",
    "            if p[tuple(f_idx)] != np.inf:\n",
    "                feasible_solution = True\n",
    "        if feasible_solution:\n",
    "            fes += 1\n",
    "        \n",
    "    performances[performances == np.inf] = np.nan\n",
    "\n",
    "    # get the indexes over the entire data structure, because we need to know which constraints were violated\n",
    "    best = np.min(best_list)\n",
    "    idx_best =  np.unravel_index(np.where(performances.flatten() == best)[0][0], performances.shape)\n",
    "    worst = np.max(best_list)\n",
    "    idx_worst = np.unravel_index(np.where(performances.flatten() == worst)[0][0], performances.shape)\n",
    "    idx_median = np.unravel_index(\n",
    "        np.where(performances.flatten() == np.nanpercentile(performances,50,interpolation='nearest'))[0][0], \n",
    "        performances.shape\n",
    "    )\n",
    "    median = performances[idx_median]\n",
    "    \n",
    "    mean = np.mean(best_list)\n",
    "    std = np.std(best_list)\n",
    "    \n",
    "    # compute # of violated constraints\n",
    "    consts_best = 0\n",
    "    consts_worst = 0\n",
    "    consts_median = 0\n",
    "    consts_median_specific = [0, 0, 0]\n",
    "    mean_violations = list()\n",
    "    for k, cost in enumerate(list(function_class.constraints(None).keys())):\n",
    "        if cost.startswith('g'):\n",
    "            if idx_best[k+1] > 0:\n",
    "                consts_best += 1\n",
    "            if idx_worst[k+1] > 0:\n",
    "                consts_worst += 1\n",
    "            if idx_median[k+1] > 0:\n",
    "                consts_median += 1\n",
    "                # add constraint violation to mean_violations\n",
    "                mean_violations.append(function_obj.constraints()[cost]['func'](solutions[idx_median]))\n",
    "                \n",
    "        if cost.startswith('h'):\n",
    "            if idx_best[k+1] > 1:\n",
    "                consts_best += 1\n",
    "            if idx_worst[k+1] > 1:\n",
    "                consts_worst += 1\n",
    "            if idx_median[k+1] > 1:\n",
    "                consts_median += 1\n",
    "                # add constraint violation to mean_violations\n",
    "                mean_violations.append(function_obj.constraints()[cost]['func'](solutions[idx_median]))\n",
    "                \n",
    "        # violation > 0.0001\n",
    "        if idx_median[k+1] == 2:\n",
    "            consts_median_specific[0] += 1\n",
    "        # violation > 0.01\n",
    "        if idx_median[k+1] == 3:\n",
    "            consts_median_specific[1] += 1\n",
    "        # violation > 1.0\n",
    "        if idx_median[k+1] == 4:\n",
    "            consts_median_specific[2] += 1\n",
    "    \n",
    "#     assert sum(consts_median_specific) == consts_median\n",
    "    results[c] = {\n",
    "        \"best_perf\": round(best, 2),\n",
    "        \"best_consts\": consts_best,\n",
    "        \"worst_perf\": round(worst, 2),\n",
    "        \"worst_consts\": consts_worst,\n",
    "        \"median_perf\": round(median, 2),\n",
    "        \"median_consts\": consts_median,\n",
    "        \"mean\": round(mean, 2),\n",
    "        \"std\": round(std, 2),\n",
    "        \"c\": consts_median_specific,\n",
    "        \"v\": round(np.mean(mean_violations), 2) if len(mean_violations) > 0 else 0,\n",
    "        \"f_rate\": round(fes / runs, 2)\n",
    "    }\n",
    "print_table(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
